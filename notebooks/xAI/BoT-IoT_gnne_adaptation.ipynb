{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7e562a1",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c41ceb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taznk/COMP4003/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dgl \n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.explain import Explainer, CaptumExplainer, DummyExplainer, GNNExplainer\n",
    "from torch_geometric.explain.metric import *\n",
    "from torch_geometric.nn.models.basic_gnn import GraphSAGE\n",
    "from torch_geometric.utils import from_dgl\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.explain import ModelConfig\n",
    "import scienceplots\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "with open('../../interm/label_encoders.pkl', 'rb') as f:\n",
    "    encoders = pickle.load(f)\n",
    "    \n",
    "def view_metrics(metrics_list, legend=None, s=3):\n",
    "    for i, metrics in enumerate(metrics_list):\n",
    "        if legend:\n",
    "            print(f'\\n{legend[i]}')\n",
    "        \n",
    "        fp, fn = metrics['softmask fidelity']\n",
    "        print(f'fid+ : {fp:.4f}\\tfid- : {fn:.4f}\\n')\n",
    "        print(f\"{'Class':<15}{'fid+':>10}{'fid-':>10}{'char':>10}\")\n",
    "        for attack in encoders['Attack'].classes_:\n",
    "            fp, fn, c = metrics[f'softmask fidelity {attack}']\n",
    "            print(f\"{attack:<15}{fp:>10.3f}{fn:>10.3f}{c:>10.3f}\")\n",
    "    \n",
    "    # plt.style.use(['science','no-latex'])\n",
    "    with plt.style.context('science'): \n",
    "           \n",
    "        for metrics in metrics_list:\n",
    "            plt.plot(metrics['s'], metrics['fid-'])\n",
    "            plt.scatter(metrics['s'], metrics['fid-'], s=s)\n",
    "        \n",
    "        plt.title('Sparsity Vs Fidelity-')\n",
    "        if legend: plt.legend(legend)\n",
    "        plt.show()\n",
    "        \n",
    "        for metrics in metrics_list:\n",
    "            plt.plot(metrics['s'], metrics['fid+'])\n",
    "            plt.scatter(metrics['s'], metrics['fid+'], s=s)\n",
    "        \n",
    "        plt.title('Sparsity Vs Fidelity+')\n",
    "        if legend: plt.legend(legend)\n",
    "        plt.show()\n",
    "        \n",
    "        for metrics in metrics_list:\n",
    "            plt.plot(metrics['s'], metrics['c'])\n",
    "            plt.scatter(metrics['s'], metrics['c'], s=s)\n",
    "        \n",
    "        plt.title('Sparsity Vs Characterisation Score')\n",
    "        if legend: plt.legend(legend)\n",
    "        plt.show()\n",
    "        \n",
    "def masked_prediction(mask, model, G, hardmask=True):\n",
    "    if not hardmask:\n",
    "        inv_mask = 1-mask\n",
    "    else:\n",
    "        inv_mask = ~mask\n",
    "        \n",
    "    y_pred = model(G.x[:, :49], G.edge_index).argmax(axis=1)\n",
    "    ym_pred = model(G.x[:, :49]*mask, G.edge_index).argmax(axis=1)\n",
    "    ymi_pred = model(G.x[:, :49]*inv_mask, G.edge_index).argmax(axis=1)\n",
    "    return y_pred, ym_pred, ymi_pred\n",
    "\n",
    "\n",
    "def fidelities(y_pred, y_mask, y_imask, y):\n",
    "    fn = ((y_pred == y).float() - (y_mask == y).float()).abs().mean()\n",
    "    fp = ((y_pred == y).float() - (y_imask == y).float()).abs().mean()\n",
    "    return fp, fn\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82bde2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLOW_START_MILLISECONDS</th>\n",
       "      <th>FLOW_END_MILLISECONDS</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>TCP_FLAGS</th>\n",
       "      <th>CLIENT_TCP_FLAGS</th>\n",
       "      <th>...</th>\n",
       "      <th>Attack</th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>x</th>\n",
       "      <th>FLOW_START_MILLISECONDS_metadata</th>\n",
       "      <th>FLOW_END_MILLISECONDS_metadata</th>\n",
       "      <th>IPV4_SRC_ADDR_metadata</th>\n",
       "      <th>L4_SRC_PORT_metadata</th>\n",
       "      <th>IPV4_DST_ADDR_metadata</th>\n",
       "      <th>L4_DST_PORT_metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.236904</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.503789</td>\n",
       "      <td>106</td>\n",
       "      <td>-0.17034</td>\n",
       "      <td>-0.2804</td>\n",
       "      <td>-0.071477</td>\n",
       "      <td>-0.149842</td>\n",
       "      <td>1.257089</td>\n",
       "      <td>1.728738</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>192.168.100.3:-1.0586554</td>\n",
       "      <td>192.168.100.149:2.6106632</td>\n",
       "      <td>[-0.23690394, -0.23692596, -0.5037887, 106.0, ...</td>\n",
       "      <td>1.526968e+12</td>\n",
       "      <td>1.526968e+12</td>\n",
       "      <td>192.168.100.3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>192.168.100.149</td>\n",
       "      <td>34502.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FLOW_START_MILLISECONDS  FLOW_END_MILLISECONDS  PROTOCOL  L7_PROTO  \\\n",
       "0                -0.236904              -0.236926 -0.503789       106   \n",
       "\n",
       "   IN_BYTES  IN_PKTS  OUT_BYTES  OUT_PKTS  TCP_FLAGS  CLIENT_TCP_FLAGS  ...  \\\n",
       "0  -0.17034  -0.2804  -0.071477 -0.149842   1.257089          1.728738  ...   \n",
       "\n",
       "   Attack                       src                        dst  \\\n",
       "0       0  192.168.100.3:-1.0586554  192.168.100.149:2.6106632   \n",
       "\n",
       "                                                   x  \\\n",
       "0  [-0.23690394, -0.23692596, -0.5037887, 106.0, ...   \n",
       "\n",
       "   FLOW_START_MILLISECONDS_metadata  FLOW_END_MILLISECONDS_metadata  \\\n",
       "0                      1.526968e+12                    1.526968e+12   \n",
       "\n",
       "   IPV4_SRC_ADDR_metadata  L4_SRC_PORT_metadata  IPV4_DST_ADDR_metadata  \\\n",
       "0           192.168.100.3                  80.0         192.168.100.149   \n",
       "\n",
       "   L4_DST_PORT_metadata  \n",
       "0               34502.0  \n",
       "\n",
       "[1 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('../../interm/BoT_test.csv')\n",
    "attrs = [c for c in test.columns if c not in (\"src\", \"dst\", \"Attack\", \"x\", \"IPV4_SRC_ADDR_metadata\", \"L4_SRC_PORT_metadata\", \n",
    "                                              \"IPV4_DST_ADDR_metadata\", \"L4_DST_PORT_metadata\") \n",
    "        #  and not c.endswith('_metadata')\n",
    "         ]\n",
    "test['x'] = test[attrs].values.tolist()\n",
    "test[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "678b04f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4021/3588832698.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(th.load('../../interm/GraphSAGE_BoTIoT.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphSAGE(49, 5, num_layers=3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_graph(data, linegraph=True):\n",
    "    G = nx.from_pandas_edgelist(data, source='src', \n",
    "                                target='dst', \n",
    "                                edge_attr=['x', 'Attack'], \n",
    "                                create_using=nx.MultiGraph()) \n",
    "    \n",
    "    G = G.to_directed()\n",
    "    g = dgl.from_networkx(G, edge_attrs=[ 'x', 'Attack'])\n",
    "    if linegraph:\n",
    "        return g.line_graph(shared=True)\n",
    "    else:\n",
    "        return g\n",
    "\n",
    "model = GraphSAGE(49,\n",
    "                  hidden_channels=256,\n",
    "                  out_channels=5,\n",
    "                  num_layers=3).to(device)\n",
    "\n",
    "model.load_state_dict(th.load('../../interm/GraphSAGE_BoTIoT.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f30550ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.5270e+12), tensor(1.5270e+12))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = to_graph(test)\n",
    "G.ndata['x'][0][-1], G.ndata['x'][0][-2] # unscaled start and stop times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2508e4",
   "metadata": {},
   "source": [
    "### Motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20c2329b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1.,  ..., 0., 0., 0.]),\n",
       " tensor([0., 0., 0.,  ..., 1., 0., 1.]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch, networkx as nx, dgl\n",
    "from torch_geometric.transforms import LineGraph\n",
    "from torch_geometric.utils import from_dgl\n",
    "\n",
    "# 1) Build NX, then RELABEL to 0..N-1 to avoid gaps/off-by-one\n",
    "nx_g = nx.from_pandas_edgelist(\n",
    "    test, source='src', target='dst',\n",
    "    edge_attr=['x', 'Attack'],\n",
    "    create_using=nx.DiGraph()\n",
    ")\n",
    "nx_g = nx.convert_node_labels_to_integers(nx_g, ordering='sorted')\n",
    "\n",
    "# 2) DGL graph + edge motifs (on *edges*)\n",
    "dgl_g = dgl.from_networkx(nx_g, edge_attrs=['x', 'Attack'])\n",
    "src, dst = dgl_g.edges()\n",
    "out_deg = dgl_g.out_degrees()\n",
    "in_deg  = dgl_g.in_degrees()\n",
    "\n",
    "scanning_star_nodes = (out_deg > 10).nonzero(as_tuple=True)[0]\n",
    "fan_nodes           = (in_deg  > 10).nonzero(as_tuple=True)[0]\n",
    "\n",
    "is_star = torch.isin(src, scanning_star_nodes).to(torch.uint8)\n",
    "is_fan  = torch.isin(dst, fan_nodes).to(torch.uint8)\n",
    "dgl_g.edata['is_star'] = is_star\n",
    "dgl_g.edata['is_fan']  = is_fan\n",
    "\n",
    "# 3) Convert to PyG and ensure num_nodes is consistent\n",
    "pyg_g = from_dgl(dgl_g)\n",
    "pyg_g.num_nodes = int(pyg_g.edge_index.max()) + 1  # guard against off-by-one\n",
    "\n",
    "# 4) Line graph (each original edge -> one LG node)\n",
    "pyg_lg = LineGraph(force_directed=True)(pyg_g)\n",
    "\n",
    "# 5) Map edge motifs to LG node features (reuse DGL edata â€” same edge order)\n",
    "E = pyg_g.edge_index.size(1)\n",
    "base_x = pyg_lg.x if pyg_lg.x is not None else torch.zeros((E, 0), dtype=torch.float)\n",
    "motifs = torch.stack([dgl_g.edata['is_star'], dgl_g.edata['is_fan']], dim=1).float()\n",
    "pyg_lg.x = torch.cat([motifs, base_x], dim=1)\n",
    "\n",
    "# Sanity check: first two columns are your motif flags\n",
    "pyg_lg.x[:, 0], pyg_lg.x[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d05455db",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_motifs = []\n",
    "for hub in scanning_star_nodes.tolist():\n",
    "    # find edges with this hub as source\n",
    "    lg_nodes = (src == hub).nonzero(as_tuple=True)[0].tolist()\n",
    "    if lg_nodes:  # only if non-empty\n",
    "        star_motifs.append(lg_nodes)\n",
    "\n",
    "fan_motifs = []\n",
    "for sink in fan_nodes.tolist():\n",
    "    # find edges with this sink as target\n",
    "    lg_nodes = (dst == sink).nonzero(as_tuple=True)[0].tolist()\n",
    "    if lg_nodes:\n",
    "        fan_motifs.append(lg_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e315a121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 47)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(star_motifs), len(fan_motifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fce3a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1975.), tensor(4727.))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyg_lg.x[:, 0].sum(), pyg_lg.x[:, 1].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5859eb88",
   "metadata": {},
   "source": [
    "### NIDS-GNNExplainer\n",
    "motif coherence reward $=  - \\lambda_{mc} \\sum_{g \\in \\text{motifs}} || m_g ||_2$\n",
    "temporal smoothness penalty $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce946e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.explain import GNNExplainer\n",
    "\n",
    "class CustomGNNExplainer(GNNExplainer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # custom params\n",
    "        self.tv_coef = 0\n",
    "        self.motif_coef = 0\n",
    "        self.leak_coef = 0\n",
    "\n",
    "        # external info you must provide\n",
    "        self.node_times = None        # tensor of time indices per node\n",
    "        self.motif_groups = []        # list of lists of node indices\n",
    "        self.leak_feat_idx = None     # indices of features that should not leak\n",
    "\n",
    "    def additional_loss_terms(self, node_mask, feat_mask):\n",
    "        reg = 0\n",
    "\n",
    "        # (1) Temporal smoothness penalty\n",
    "        if self.node_times is not None:\n",
    "            order = torch.argsort(self.node_times)\n",
    "            diffs = torch.abs(node_mask[order][1:] - node_mask[order][:-1])\n",
    "            reg = reg + self.tv_coef * diffs.sum()\n",
    "\n",
    "        # (2) Motif group coherence (group-lasso style)\n",
    "        for g in self.motif_groups:\n",
    "            # - not + ?\n",
    "            reg = reg - self.motif_coef * torch.norm(node_mask[g], p=2)\n",
    "\n",
    "        # (3) Leakage penalty\n",
    "        if self.leak_feat_idx is not None and feat_mask is not None:\n",
    "            reg = reg + self.leak_coef * feat_mask[self.leak_feat_idx].abs().sum()\n",
    "\n",
    "        return reg\n",
    "\n",
    "    def loss(self, log_logits, pred_label, node_mask, feat_mask):\n",
    "        \"\"\"Override base loss by adding extra penalties.\"\"\"\n",
    "        base_loss = super().loss(log_logits, pred_label, node_mask, feat_mask)\n",
    "        reg_loss = self.additional_loss_terms(node_mask, feat_mask)\n",
    "        return base_loss + reg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9479cd1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29760, 49])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.x[:, :49].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938aff7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Explanation(node_mask=[29760, 49], target=[29760], x=[29760, 49], edge_index=[2, 5405122])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=CustomGNNExplainer(epochs=50),\n",
    "    # explanation_type='model',\n",
    "    explanation_type='phenomenon',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type=None,\n",
    "    model_config=ModelConfig(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='raw',\n",
    "    ),\n",
    ")  \n",
    "\n",
    "G = from_dgl(G)\n",
    "\n",
    "explainer.node_times = G.x[:, 50] # start times  \n",
    "explainer.motif_groups = star_motifs + fan_motifs\n",
    "explainer.leak_feat_idx = torch.tensor([0])           # pretend feature 0 leaks\n",
    "\n",
    "explainer.tv_coef = 1\n",
    "explainer.motif_coef = 0.5\n",
    "explainer.leak_coef = 2\n",
    "\n",
    "explanation = explainer(\n",
    "        x=G.x[:, :49].to(device),\n",
    "        edge_index=G.edge_index.to(device),\n",
    "        target=G.Attack,\n",
    ")\n",
    "\n",
    "explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bf92e7",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbed453b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [01:13<00:00,  8.15s/it]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from torch_geometric.explain.metric import fidelity, characterization_score\n",
    "\n",
    "metrics = {'fid+': [], 'fid-': [], 's': [], 'c': [], 'k': []}\n",
    "\n",
    "explanation_cp = copy.deepcopy(explanation)\n",
    "\n",
    "for s in tqdm(np.arange(0.1, 1, 0.1)):\n",
    "    flat_mask = explanation.node_mask.flatten()\n",
    "    k = int(s * flat_mask.numel())\n",
    "    threshold = torch.topk(flat_mask, k).values[-1]\n",
    "    \n",
    "    new_mask = (explanation.node_mask >= threshold).float()\n",
    "    explanation_cp.node_mask = new_mask\n",
    "    \n",
    "    fp, fn = fidelity(explainer, explanation_cp)\n",
    "    metrics['fid+'].append(fp)\n",
    "    metrics['fid-'].append(fn)\n",
    "    \n",
    "    c = characterization_score(fp, fn) if (fp * fn) != 0 else 0\n",
    "    metrics['c'].append(c)\n",
    "    metrics['s'].append(s)\n",
    "    metrics['k'].append(k)\n",
    "    \n",
    "    \n",
    "metrics['softmask fidelity'] = fidelity(explainer, explanation)\n",
    "\n",
    "y_pred, ym_pred, ymi_pred = masked_prediction(\n",
    "    explanation.node_mask, model, G, hardmask=False)\n",
    "\n",
    "for idx in range(5):\n",
    "    attack = encoders['Attack'].inverse_transform([idx])[0]\n",
    "    fp, fn = fidelities(y_pred= y_pred == idx, \n",
    "                        y_mask= ym_pred == idx, \n",
    "                        y_imask= ymi_pred == idx,\n",
    "                        y= G.Attack==idx)\n",
    "\n",
    "    w = (G.Attack==idx).float().mean()\n",
    "    c = characterization_score(fp, fn, \n",
    "                               pos_weight=w, \n",
    "                               neg_weight=1-w) if fp*fn > 0 else 0\n",
    "    \n",
    "    metrics[f'softmask fidelity {attack}'] = fp, fn, c\n",
    "     \n",
    "view_metrics([metrics])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
