{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7e562a1",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c41ceb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taznk/COMP4003/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dgl \n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.explain import Explainer, CaptumExplainer, DummyExplainer, GNNExplainer\n",
    "from torch_geometric.explain.metric import *\n",
    "from torch_geometric.nn.models.basic_gnn import GraphSAGE\n",
    "from torch_geometric.utils import from_dgl\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.explain import ModelConfig\n",
    "import scienceplots\n",
    "from explanations import *\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82bde2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLOW_START_MILLISECONDS</th>\n",
       "      <th>FLOW_END_MILLISECONDS</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>TCP_FLAGS</th>\n",
       "      <th>CLIENT_TCP_FLAGS</th>\n",
       "      <th>...</th>\n",
       "      <th>Attack</th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>x</th>\n",
       "      <th>FLOW_START_MILLISECONDS_metadata</th>\n",
       "      <th>FLOW_END_MILLISECONDS_metadata</th>\n",
       "      <th>IPV4_SRC_ADDR_metadata</th>\n",
       "      <th>L4_SRC_PORT_metadata</th>\n",
       "      <th>IPV4_DST_ADDR_metadata</th>\n",
       "      <th>L4_DST_PORT_metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.236904</td>\n",
       "      <td>-0.236926</td>\n",
       "      <td>-0.503789</td>\n",
       "      <td>106</td>\n",
       "      <td>-0.17034</td>\n",
       "      <td>-0.2804</td>\n",
       "      <td>-0.071477</td>\n",
       "      <td>-0.149842</td>\n",
       "      <td>1.257089</td>\n",
       "      <td>1.728738</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>192.168.100.3:-1.0586554</td>\n",
       "      <td>192.168.100.149:2.6106632</td>\n",
       "      <td>[-0.23690394, -0.23692596, -0.5037887, 106.0, ...</td>\n",
       "      <td>1.526968e+12</td>\n",
       "      <td>1.526968e+12</td>\n",
       "      <td>192.168.100.3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>192.168.100.149</td>\n",
       "      <td>34502.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FLOW_START_MILLISECONDS  FLOW_END_MILLISECONDS  PROTOCOL  L7_PROTO  \\\n",
       "0                -0.236904              -0.236926 -0.503789       106   \n",
       "\n",
       "   IN_BYTES  IN_PKTS  OUT_BYTES  OUT_PKTS  TCP_FLAGS  CLIENT_TCP_FLAGS  ...  \\\n",
       "0  -0.17034  -0.2804  -0.071477 -0.149842   1.257089          1.728738  ...   \n",
       "\n",
       "   Attack                       src                        dst  \\\n",
       "0       0  192.168.100.3:-1.0586554  192.168.100.149:2.6106632   \n",
       "\n",
       "                                                   x  \\\n",
       "0  [-0.23690394, -0.23692596, -0.5037887, 106.0, ...   \n",
       "\n",
       "   FLOW_START_MILLISECONDS_metadata  FLOW_END_MILLISECONDS_metadata  \\\n",
       "0                      1.526968e+12                    1.526968e+12   \n",
       "\n",
       "   IPV4_SRC_ADDR_metadata  L4_SRC_PORT_metadata  IPV4_DST_ADDR_metadata  \\\n",
       "0           192.168.100.3                  80.0         192.168.100.149   \n",
       "\n",
       "   L4_DST_PORT_metadata  \n",
       "0               34502.0  \n",
       "\n",
       "[1 rows x 59 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('../../interm/BoT_test.csv')\n",
    "attrs = [c for c in test.columns if c not in (\"src\", \"dst\", \"Attack\", \"x\", \"IPV4_SRC_ADDR_metadata\", \"L4_SRC_PORT_metadata\", \n",
    "                                              \"IPV4_DST_ADDR_metadata\", \"L4_DST_PORT_metadata\") \n",
    "        #  and not c.endswith('_metadata')\n",
    "         ]\n",
    "test['x'] = test[attrs].values.tolist()\n",
    "test[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "678b04f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1949/3588832698.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(th.load('../../interm/GraphSAGE_BoTIoT.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphSAGE(49, 5, num_layers=3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_graph(data, linegraph=True):\n",
    "    G = nx.from_pandas_edgelist(data, source='src', \n",
    "                                target='dst', \n",
    "                                edge_attr=['x', 'Attack'], \n",
    "                                create_using=nx.MultiGraph()) \n",
    "    \n",
    "    G = G.to_directed()\n",
    "    g = dgl.from_networkx(G, edge_attrs=[ 'x', 'Attack'])\n",
    "    if linegraph:\n",
    "        return g.line_graph(shared=True)\n",
    "    else:\n",
    "        return g\n",
    "\n",
    "model = GraphSAGE(49,\n",
    "                  hidden_channels=256,\n",
    "                  out_channels=5,\n",
    "                  num_layers=3).to(device)\n",
    "\n",
    "model.load_state_dict(th.load('../../interm/GraphSAGE_BoTIoT.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f30550ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.5270e+12), tensor(1.5270e+12))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = to_graph(test)\n",
    "G.ndata['x'][0][-1], G.ndata['x'][0][-2] # unscaled start and stop times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2508e4",
   "metadata": {},
   "source": [
    "### Motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20c2329b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12631, 51])\n",
      "torch.Size([12631, 53])\n"
     ]
    }
   ],
   "source": [
    "import torch, networkx as nx, dgl\n",
    "from torch_geometric.transforms import LineGraph\n",
    "from torch_geometric.utils import from_dgl\n",
    "\n",
    "# 1) Build NX, then RELABEL to 0..N-1 to avoid gaps/off-by-one\n",
    "nx_g = nx.from_pandas_edgelist(\n",
    "    test, source='src', target='dst',\n",
    "    edge_attr=['x', 'Attack'],\n",
    "    create_using=nx.DiGraph()\n",
    ")\n",
    "# nx_g = nx.convert_node_labels_to_integers(nx_g, ordering='sorted') # ! ?\n",
    "\n",
    "# 2) DGL graph + edge motifs (on *edges*)\n",
    "dgl_g = dgl.from_networkx(nx_g, edge_attrs=['x', 'Attack'])\n",
    "src, dst = dgl_g.edges()\n",
    "out_deg = dgl_g.out_degrees()\n",
    "in_deg  = dgl_g.in_degrees()\n",
    "\n",
    "scanning_star_nodes = (out_deg > 10).nonzero(as_tuple=True)[0]\n",
    "fan_nodes           = (in_deg  > 10).nonzero(as_tuple=True)[0]\n",
    "\n",
    "is_star = torch.isin(src, scanning_star_nodes).to(torch.uint8)\n",
    "is_fan  = torch.isin(dst, fan_nodes).to(torch.uint8)\n",
    "new = torch.vstack([is_star, is_fan])\n",
    "\n",
    "print(dgl_g.edata['x'].shape)\n",
    "dgl_g.edata['x'] = torch.hstack([dgl_g.edata['x'], new.T])\n",
    "print(dgl_g.edata['x'].shape)\n",
    "\n",
    "dgl_lg = dgl_g.line_graph(shared=True)\n",
    "pyg_lg = from_dgl(dgl_g)\n",
    "pyg_lg.num_nodes = int(pyg_lg.edge_index.max()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d05455db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# star_motifs = []\n",
    "# for hub in scanning_star_nodes.tolist():\n",
    "#     # find edges with this hub as source\n",
    "#     lg_nodes = (src == hub).nonzero(as_tuple=True)[0].tolist()\n",
    "#     if lg_nodes:  # only if non-empty\n",
    "#         star_motifs.append(lg_nodes)\n",
    "\n",
    "# fan_motifs = []\n",
    "# for sink in fan_nodes.tolist():\n",
    "#     # find edges with this sink as target\n",
    "#     lg_nodes = (dst == sink).nonzero(as_tuple=True)[0].tolist()\n",
    "#     if lg_nodes:\n",
    "#         fan_motifs.append(lg_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2fe0bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1975.), tensor(4727.))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyg_lg.x[:, 51].sum(), pyg_lg.x[:, 52].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5859eb88",
   "metadata": {},
   "source": [
    "### NIDS-GNNExplainer\n",
    "- motif coherence reward $= - \\lambda_{mc} \\cdot \\sum_{g \\in \\text{motifs}} || m_g ||_2$\n",
    "- temporal smoothness penalty =  $\\lambda_{ts} \\cdot \\text{exp}(\\frac{-(t_i - t_j)^2}{2\\sigma^2}) ||m_i - m_j||^2$\n",
    "- threshhold sparsity penalty = $1/N \\sum \\mathcal{I}(n > k) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cce946e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.explain import GNNExplainer\n",
    "\n",
    "class CustomGNNExplainer(GNNExplainer):\n",
    "    \n",
    "    params = {\n",
    "        'ts_coef': 0,\n",
    "        'motif_coef': 0,\n",
    "        'sparsity_coef': 0,\n",
    "        'sparsity_threshold': 0\n",
    "    }\n",
    "    \n",
    "    epoch_metrics = {\n",
    "        'temporal smoothness penalty': [],\n",
    "        'sparsity penalty': [],\n",
    "        'motif coherance reward': [],\n",
    "        'base loss': [],\n",
    "    }\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        node_times, \n",
    "        motif_groups, \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.params.update(kwargs)\n",
    "        self.node_times = node_times \n",
    "        self.motif_groups = motif_groups\n",
    "\n",
    "    def temporal_smoothness(self, node_mask):\n",
    "        order = torch.argsort(self.node_times)\n",
    "        times = self.node_times[order]\n",
    "        time_diffs = (times[1:] - times[:-1])\n",
    "        ordered_node_importances = node_mask[order].mean(axis=1)\n",
    "        w_ij = torch.exp(- (time_diffs**2) / (2 * time_diffs.std()**2))\n",
    "        spread = (w_ij * (ordered_node_importances[1:] \n",
    "                          - ordered_node_importances[:-1]  ** 2)).sum()\n",
    "        \n",
    "        return self.params['ts_coef'] * spread\n",
    "    \n",
    "    def motif_coherance(self, node_mask):\n",
    "        return sum([\n",
    "            self.params['motif_coef'] * torch.norm(node_mask[g], p=2)\n",
    "            for g in self.motif_groups\n",
    "        ]) / len(self.motif_groups)\n",
    "\n",
    "    def sparsity(self, node_mask):\n",
    "        sparsity = (node_mask > self.params['sparsity_threshhold']).float().mean()\n",
    "        return self.params['sparsity_coef'] * sparsity\n",
    "\n",
    "    def additional_loss_terms(self, node_mask):\n",
    "        reg = 0\n",
    "\n",
    "        ts = self.temporal_smoothness(node_mask)\n",
    "        self.epoch_metrics['temporal smoothness penalty'].append(ts)\n",
    "        print(f'temporal smoothness penalty {ts}')\n",
    "        reg += ts\n",
    "\n",
    "        mc = self.motif_coherance(node_mask)\n",
    "        self.epoch_metrics['motif coherance reward'].append(mc)\n",
    "        print(f'motif coherance reward: {mc}')\n",
    "        reg -= mc\n",
    "        \n",
    "        sp = self.sparsity(node_mask)\n",
    "        self.epoch_metrics['sparsity penalty'].append(sp)\n",
    "        print(f'sparsity penalty {sp}')\n",
    "        reg += sp\n",
    "        \n",
    "        return reg\n",
    "\n",
    "    def plot_descent(self):\n",
    "        with plt.style.context('science'): \n",
    "            for l in self.epoch_metrics.values():\n",
    "                plt.plot(l)\n",
    "            plt.legend(self.epoch_metrics.keys())\n",
    "            plt.show()\n",
    "\n",
    "    # def _loss(self, log_logits, pred_label, node_mask, feat_mask):\n",
    "    def _loss(self, y_hat: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        base_loss = super()._loss(y_hat, y)\n",
    "        reg_loss = self.additional_loss_terms(self.node_mask)\n",
    "        print(f'base_loss: {base_loss}')\n",
    "        print(f'total loss: {base_loss + reg_loss}\\n')\n",
    "        self.epoch_metrics['base loss'].append(base_loss)\n",
    "        return base_loss + reg_loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938aff7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDoS\n",
      "torch.Size([10168, 53])\n",
      "torch.Size([10168])\n",
      "temporal smoothness penalty -0.0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 10179 is out of bounds for dimension 0 with size 10168",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28mprint\u001b[39m(subG.Attack.shape)\n\u001b[32m     50\u001b[39m x = subG.x[:, :\u001b[32m49\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m explanation = \u001b[43mexplainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubG\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubG\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAttack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m metrics[attack] = explanation \n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# softmask metrics\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch_geometric/explain/explainer.py:205\u001b[39m, in \u001b[36mExplainer.__call__\u001b[39m\u001b[34m(self, x, edge_index, target, index, **kwargs)\u001b[39m\n\u001b[32m    202\u001b[39m training = \u001b[38;5;28mself\u001b[39m.model.training\n\u001b[32m    203\u001b[39m \u001b[38;5;28mself\u001b[39m.model.eval()\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m explanation = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43malgorithm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28mself\u001b[39m.model.train(training)\n\u001b[32m    216\u001b[39m \u001b[38;5;66;03m# Add explainer objectives to the `Explanation` object:\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch_geometric/explain/algorithm/gnn_explainer.py:87\u001b[39m, in \u001b[36mGNNExplainer.forward\u001b[39m\u001b[34m(self, model, x, edge_index, target, index, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHeterogeneous graphs not yet supported in \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     85\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m node_mask = \u001b[38;5;28mself\u001b[39m._post_process_mask(\n\u001b[32m     90\u001b[39m     \u001b[38;5;28mself\u001b[39m.node_mask,\n\u001b[32m     91\u001b[39m     \u001b[38;5;28mself\u001b[39m.hard_node_mask,\n\u001b[32m     92\u001b[39m     apply_sigmoid=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     93\u001b[39m )\n\u001b[32m     94\u001b[39m edge_mask = \u001b[38;5;28mself\u001b[39m._post_process_mask(\n\u001b[32m     95\u001b[39m     \u001b[38;5;28mself\u001b[39m.edge_mask,\n\u001b[32m     96\u001b[39m     \u001b[38;5;28mself\u001b[39m.hard_edge_mask,\n\u001b[32m     97\u001b[39m     apply_sigmoid=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     98\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch_geometric/explain/algorithm/gnn_explainer.py:137\u001b[39m, in \u001b[36mGNNExplainer._train\u001b[39m\u001b[34m(self, model, x, edge_index, target, index, **kwargs)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    135\u001b[39m     y_hat, y = y_hat[index], y[index]\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m loss.backward()\n\u001b[32m    140\u001b[39m optimizer.step()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mCustomGNNExplainer._loss\u001b[39m\u001b[34m(self, y_hat, y)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, y_hat: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n\u001b[32m     82\u001b[39m     base_loss = \u001b[38;5;28msuper\u001b[39m()._loss(y_hat, y)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     reg_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madditional_loss_terms\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mbase_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     85\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtotal loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_loss\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39mreg_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 61\u001b[39m, in \u001b[36mCustomGNNExplainer.additional_loss_terms\u001b[39m\u001b[34m(self, node_mask)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtemporal smoothness penalty \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mts\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     59\u001b[39m reg += ts\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m mc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmotif_coherance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28mself\u001b[39m.epoch_metrics[\u001b[33m'\u001b[39m\u001b[33mmotif coherance reward\u001b[39m\u001b[33m'\u001b[39m].append(mc)\n\u001b[32m     63\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmotif coherance reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mCustomGNNExplainer.motif_coherance\u001b[39m\u001b[34m(self, node_mask)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmotif_coherance\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_mask):\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43m[\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmotif_coef\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmotif_groups\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m) / \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.motif_groups)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmotif_coherance\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_mask):\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m([\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m         \u001b[38;5;28mself\u001b[39m.params[\u001b[33m'\u001b[39m\u001b[33mmotif_coef\u001b[39m\u001b[33m'\u001b[39m] * torch.norm(\u001b[43mnode_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mg\u001b[49m\u001b[43m]\u001b[49m, p=\u001b[32m2\u001b[39m)\n\u001b[32m     46\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.motif_groups\n\u001b[32m     47\u001b[39m     ]) / \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.motif_groups)\n",
      "\u001b[31mIndexError\u001b[39m: index 10179 is out of bounds for dimension 0 with size 10168"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics = {}\n",
    "for attack, subG in yield_class_graphs(pyg_lg):\n",
    "    if attack == 'Benign': \n",
    "        continue\n",
    "    \n",
    "    print(attack)\n",
    "\n",
    "    is_star, is_fan = subG.x[:, 51], subG.x[:, 52]\n",
    "    end_times, start_times = subG.x[:, 50], subG.x[:, 49]\n",
    "    \n",
    "    scanning_star_nodes = is_star.nonzero(as_tuple=True)[0]\n",
    "    fan_nodes = is_fan.nonzero(as_tuple=True)[0]\n",
    "    \n",
    "    star_motifs = []\n",
    "    for hub in scanning_star_nodes.tolist():\n",
    "        lg_nodes = (src == hub).nonzero(as_tuple=True)[0].tolist()\n",
    "        if lg_nodes: \n",
    "            star_motifs.append(lg_nodes)\n",
    "\n",
    "    fan_motifs = []\n",
    "    for sink in fan_nodes.tolist():\n",
    "        lg_nodes = (dst == sink).nonzero(as_tuple=True)[0].tolist()\n",
    "        if lg_nodes:\n",
    "            fan_motifs.append(lg_nodes)\n",
    "    \n",
    "    explainer = Explainer(\n",
    "        model=model,\n",
    "        algorithm=CustomGNNExplainer(\n",
    "            epochs=100, \n",
    "            node_times = start_times,\n",
    "            motif_groups = (star_motifs + fan_motifs),\n",
    "            tv_coef = 1.0,\n",
    "            motif_coef = 0.01,\n",
    "            sparsity_coef = 1.0,\n",
    "            sparsity_threshhold = 0.5,\n",
    "        ),\n",
    "        explanation_type='phenomenon',\n",
    "        node_mask_type='attributes',\n",
    "        edge_mask_type=None,\n",
    "        model_config=ModelConfig(\n",
    "            mode='multiclass_classification',\n",
    "            task_level='node',\n",
    "            return_type='raw',\n",
    "        ),\n",
    "    )  \n",
    "    \n",
    "    print(subG.x.shape)\n",
    "    print(subG.Attack.shape)\n",
    "\n",
    "    x = subG.x[:, :49]\n",
    "    explanation = explainer(\n",
    "        x=x,\n",
    "        edge_index=subG.edge_index.to(device),\n",
    "        target=subG.Attack,\n",
    "    )\n",
    "    \n",
    "    metrics[attack] = explanation \n",
    "    \n",
    "    # softmask metrics\n",
    "    fp, fn, c = evaluate_softmask(model, subG, explanation.node_mask)\n",
    "    metrics[f'{attack} softmask metrics'] = fp, fn, c\n",
    "    print(f'\\tfp: {fp:.3f}')\n",
    "    print(f'\\tfn: {fn:.3f}')\n",
    "    print(f'\\tc: {c:.3f}')\n",
    "    \n",
    "    # sparsity curve\n",
    "    metrics[f'{attack} sparsity curve'] = evaluate_sparsity_threshholds(\n",
    "        model, subG, explanation.node_mask)\n",
    "    \n",
    "    # regularization curves\n",
    "    print(attack)\n",
    "    with plt.style.context('science'): \n",
    "        for m, l in explainer.algorithm.epoch_metrics.items():\n",
    "            y = [ll.detach().numpy() for ll in l]\n",
    "            plt.plot(y)\n",
    "\n",
    "        plt.legend(explainer.algorithm.epoch_metrics.keys())\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07b860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sparsity curves\n",
    "with plt.style.context('science'): \n",
    "    for metric in ('fid-', 'fid+', 'c'):\n",
    "        print(metric)\n",
    "        for attack in le['Attack'].classes_:\n",
    "            if attack == 'Benign': \n",
    "                continue\n",
    "\n",
    "            m = metrics[f'{attack} sparsity curve']\n",
    "            plt.plot(m['s'], m[metric])\n",
    "        \n",
    "        plt.legend(le['Attack'].classes_[1:])\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a46d6fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../interm/nidse_metrics', 'wb') as f:\n",
    "    pickle.dump(metrics, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
