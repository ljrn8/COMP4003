{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76802cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "import torch as th\n",
    "from torch_geometric.explain import Explainer, CaptumExplainer\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch_geometric.nn.models.basic_gnn import GraphSAGE\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7930961",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taznk/COMP4003/venv/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "/home/taznk/COMP4003/venv/lib/python3.11/site-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
      "  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n",
      "/tmp/ipykernel_936259/3043898915.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(th.load('interm/GraphSAGE_BoTIoT.pth'))\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.utils import from_dgl\n",
    "\n",
    "with open('interm/BoT-IoT_reduced_linegraph_jul29.pkl', 'rb') as f:\n",
    "    G = pickle.load(f)\n",
    "    \n",
    "test_loader = NeighborLoader(\n",
    "    G,\n",
    "    num_neighbors=[10] * 3,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=6,\n",
    "    input_nodes=G.test_mask\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f50c4df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_936259/2760749086.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(th.load('interm/GraphSAGE_BoTIoT.pth'))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model = GraphSAGE(\n",
    "    49,\n",
    "    hidden_channels=256,\n",
    "    out_channels=5,\n",
    "    num_layers=3,\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(th.load('interm/GraphSAGE_BoTIoT.pth'))\n",
    "model.eval()\n",
    "\n",
    "def fidelity(pred_orig, pred_masked, y):\n",
    "    return  (\n",
    "        np.array(pred_orig == y, dtype=int) - np.array(pred_masked == y, dtype=int)\n",
    "    ).mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03792a56",
   "metadata": {},
   "source": [
    "### GNNEx, DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55e9048c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/233 [00:44<21:03,  5.62s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, explainer_object \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[32m     25\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mGNNE\u001b[39m\u001b[33m'\u001b[39m: GNNExplainer(\u001b[32m100\u001b[39m),\n\u001b[32m     26\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mDE\u001b[39m\u001b[33m'\u001b[39m: DummyExplainer(),\n\u001b[32m     27\u001b[39m     \u001b[38;5;66;03m# 'IG': CaptumExplainer( 'IntegratedGradients'),\u001b[39;00m\n\u001b[32m     28\u001b[39m     \u001b[38;5;66;03m# 'SA': CaptumExplainer('Saliency')\u001b[39;00m\n\u001b[32m     29\u001b[39m     }.items():\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mprint\u001b[39m(name)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     explanations[name] = \u001b[43mexpl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mG\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexplainer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mExplainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m            \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexplainer_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexplanation_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnode_mask_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mattributes\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m            \u001b[49m\u001b[43medge_mask_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \n\u001b[32m     42\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mModelConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmulticlass_classification\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtask_level\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnode\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mraw\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m     \u001b[38;5;28mprint\u001b[39m(explanations[name].shape, explanations[name])\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mexpl\u001b[39m\u001b[34m(explainer, G)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(test_loader):\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m batch.edge_index.shape[\u001b[32m0\u001b[39m] == \u001b[32m2\u001b[39m\n\u001b[32m     13\u001b[39m     explanations.append(\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[43mexplainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m            \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m            \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m explanations\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch_geometric/explain/explainer.py:205\u001b[39m, in \u001b[36mExplainer.__call__\u001b[39m\u001b[34m(self, x, edge_index, target, index, **kwargs)\u001b[39m\n\u001b[32m    202\u001b[39m training = \u001b[38;5;28mself\u001b[39m.model.training\n\u001b[32m    203\u001b[39m \u001b[38;5;28mself\u001b[39m.model.eval()\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m explanation = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43malgorithm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28mself\u001b[39m.model.train(training)\n\u001b[32m    216\u001b[39m \u001b[38;5;66;03m# Add explainer objectives to the `Explanation` object:\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch_geometric/explain/algorithm/gnn_explainer.py:87\u001b[39m, in \u001b[36mGNNExplainer.forward\u001b[39m\u001b[34m(self, model, x, edge_index, target, index, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHeterogeneous graphs not yet supported in \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     85\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m node_mask = \u001b[38;5;28mself\u001b[39m._post_process_mask(\n\u001b[32m     90\u001b[39m     \u001b[38;5;28mself\u001b[39m.node_mask,\n\u001b[32m     91\u001b[39m     \u001b[38;5;28mself\u001b[39m.hard_node_mask,\n\u001b[32m     92\u001b[39m     apply_sigmoid=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     93\u001b[39m )\n\u001b[32m     94\u001b[39m edge_mask = \u001b[38;5;28mself\u001b[39m._post_process_mask(\n\u001b[32m     95\u001b[39m     \u001b[38;5;28mself\u001b[39m.edge_mask,\n\u001b[32m     96\u001b[39m     \u001b[38;5;28mself\u001b[39m.hard_edge_mask,\n\u001b[32m     97\u001b[39m     apply_sigmoid=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     98\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch_geometric/explain/algorithm/gnn_explainer.py:139\u001b[39m, in \u001b[36mGNNExplainer._train\u001b[39m\u001b[34m(self, model, x, edge_index, target, index, **kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m     y_hat, y = y_hat[index], y[index]\n\u001b[32m    137\u001b[39m loss = \u001b[38;5;28mself\u001b[39m._loss(y_hat, y)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m optimizer.step()\n\u001b[32m    142\u001b[39m \u001b[38;5;66;03m# In the first iteration, we collect the nodes and edges that are\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# involved into making the prediction. These are all the nodes and\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;66;03m# edges with gradient != 0 (without regularization applied).\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch/_tensor.py:521\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    512\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    513\u001b[39m         Tensor.backward,\n\u001b[32m    514\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    519\u001b[39m         inputs=inputs,\n\u001b[32m    520\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch/autograd/__init__.py:289\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    284\u001b[39m     retain_graph = create_graph\n\u001b[32m    286\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch/autograd/graph.py:768\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    766\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    767\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m768\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    769\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "from torch_geometric.explain.algorithm import DummyExplainer\n",
    "from torch_geometric.explain import Explainer, ModelConfig\n",
    "from torch_geometric.explain.algorithm import CaptumExplainer, GNNExplainer\n",
    "\n",
    "def expl(explainer, G):\n",
    "    explanations = []\n",
    "    for batch in tqdm(test_loader):\n",
    "        assert batch.edge_index.shape[0] == 2\n",
    "        explanations.append(\n",
    "            explainer(\n",
    "                x=batch.x.to(device),\n",
    "                edge_index=batch.edge_index.to(device),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    return explanations \n",
    "\n",
    "explanations = {}\n",
    "\n",
    "for name, explainer_object in {\n",
    "    'GNNE': GNNExplainer(100),\n",
    "    'DE': DummyExplainer(),\n",
    "    # 'IG': CaptumExplainer( 'IntegratedGradients'),\n",
    "    # 'SA': CaptumExplainer('Saliency')\n",
    "    }.items():\n",
    "\n",
    "    print(name)\n",
    "    explanations[name] = expl(\n",
    "        G=copy.deepcopy(G),\n",
    "        explainer=Explainer(\n",
    "            model=model,\n",
    "            algorithm=explainer_object,\n",
    "            explanation_type='model',\n",
    "            node_mask_type='attributes',\n",
    "            edge_mask_type=None,\n",
    "            model_config=ModelConfig(\n",
    "                mode='multiclass_classification',\n",
    "                task_level='node',\n",
    "                return_type='raw',\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    print(explanations[name].shape, explanations[name])\n",
    "    \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb107867",
   "metadata": {},
   "source": [
    "### IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0175c920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 233/233 [08:36<00:00,  2.22s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def integrated_gradients_batch(x, edge_index, targets, model, baseline, steps):\n",
    "    device = x.device\n",
    "    if baseline is None:\n",
    "        baseline = torch.zeros_like(x, device=device)\n",
    "\n",
    "    diff = x - baseline\n",
    "    total_grads = torch.zeros_like(x, device=device)\n",
    "\n",
    "    for alpha in torch.linspace(0.0, 1.0, steps, device=device):\n",
    "        x_scaled = baseline + alpha * diff\n",
    "        x_scaled.requires_grad_(True)\n",
    "\n",
    "        # forward pass\n",
    "        out = model(x_scaled, edge_index)\n",
    "        \n",
    "        # pick the logit for each root node & assume root nodes are first B rows\n",
    "        batch_size = targets.size(0)\n",
    "        sel = out[:batch_size, :] \n",
    "        chosen = sel[torch.arange(batch_size), targets]\n",
    "\n",
    "        # sum to get a scalar and backprop\n",
    "        model.zero_grad()\n",
    "        torch.autograd.backward(chosen.sum(), retain_graph=True)\n",
    "        grads = x_scaled.grad\n",
    "\n",
    "        total_grads += grads\n",
    "        x_scaled.grad.zero_()\n",
    "\n",
    "    # average gradient then scale by input delta\n",
    "    avg_grads = total_grads / steps\n",
    "    attributions = diff * avg_grads \n",
    "\n",
    "    return attributions\n",
    "\n",
    "\n",
    "model.eval()\n",
    "all_attr, all_delta = [], []\n",
    "\n",
    "for batch in tqdm(test_loader):\n",
    "    batch = batch.to(device)\n",
    "    x = batch.x\n",
    "    edge_index = batch.edge_index\n",
    "    root_idx = torch.arange(batch.batch_size, device=device)\n",
    "    targets = batch.Attack[root_idx]\n",
    "\n",
    "    # compute attributions\n",
    "    ig_attr = integrated_gradients_batch(\n",
    "        x=x,\n",
    "        edge_index=edge_index,\n",
    "        targets=targets,\n",
    "        model=model,\n",
    "        baseline=torch.zeros_like(x),\n",
    "        steps=100\n",
    "    )\n",
    "\n",
    "    # extract only root nodes’ attributions\n",
    "    root_attr = ig_attr[root_idx]\n",
    "    all_attr.append(root_attr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a9f225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_936259/2760749086.py:15: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  np.array(pred_orig == y, dtype=int) - np.array(pred_masked == y, dtype=int)\n",
      "1it [00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:01,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:01,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:03,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:04,  1.15it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Prediction after masking\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     out_masked = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_masked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m[root_idx]\n\u001b[32m     39\u001b[39m     pred_masked = out_masked.argmax(dim=\u001b[32m1\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# !!\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Fidelity: how often does prediction CHANGE after removing unimportant features?\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# fidelity = (pred_orig != pred_masked).float().mean().item()\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch_geometric/nn/models/basic_gnn.py:256\u001b[39m, in \u001b[36mBasicGNN.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_weight, edge_attr, batch, batch_size, num_sampled_nodes_per_hop, num_sampled_edges_per_hop)\u001b[39m\n\u001b[32m    254\u001b[39m     x = conv(x, edge_index, edge_attr=edge_attr)\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     x = \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i < \u001b[38;5;28mself\u001b[39m.num_layers - \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.jk_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    259\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.act \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.act_first:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch_geometric/nn/conv/sage_conv.py:139\u001b[39m, in \u001b[36mSAGEConv.forward\u001b[39m\u001b[34m(self, x, edge_index, size)\u001b[39m\n\u001b[32m    137\u001b[39m x_r = x[\u001b[32m1\u001b[39m]\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.root_weight \u001b[38;5;129;01mand\u001b[39;00m x_r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     out = out + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlin_r\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_r\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.normalize:\n\u001b[32m    142\u001b[39m     out = F.normalize(out, p=\u001b[32m2.\u001b[39m, dim=-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch_geometric/nn/dense/linear.py:147\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m    142\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Forward pass.\u001b[39;00m\n\u001b[32m    143\u001b[39m \n\u001b[32m    144\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[33;03m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[32m    146\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "fidelity_plus, fidelity_minus = {}, {}\n",
    "\n",
    "for batch, attr in tqdm(zip(test_loader, all_attr)):\n",
    "    batch = batch.to(device)\n",
    "    x = batch.x.clone()\n",
    "    y = batch.Attack.clone()\n",
    "    edge_index = batch.edge_index\n",
    "    root_idx = torch.arange(batch.batch_size, device=device)\n",
    "    targets = batch.Attack[root_idx]\n",
    "\n",
    "    # pred\n",
    "    with torch.no_grad():\n",
    "        out_orig = model(x, edge_index)[root_idx]\n",
    "        pred_orig = out_orig.argmax(dim=1)\n",
    "        \n",
    "    for sparsity_percent in np.arange(0, 0.2, 0.005):\n",
    "        abs_attr = attr.abs()\n",
    "        k = int(sparsity_percent * x.size(1))\n",
    "        topk_idx = abs_attr.topk(k, dim=1).indices\n",
    "\n",
    "        mask = torch.zeros_like(attr, device=device) \n",
    "        mask.scatter_(1, topk_idx, 1) \n",
    "\n",
    "        # Mask input features\n",
    "        x_masked = x.clone()\n",
    "        x_masked[root_idx] = x_masked[root_idx] * mask # ! only masks the root nodes ??\n",
    "\n",
    "        # Prediction after masking\n",
    "        with torch.no_grad():\n",
    "            out_masked = model(x_masked, edge_index)[root_idx]\n",
    "            pred_masked = out_masked.argmax(dim=1)\n",
    "            \n",
    "        # fidelity = (pred_orig != pred_masked).float().mean().item()\n",
    "        fidelity_minus[sparsity_percent] = fidelity(pred_orig, pred_masked, y[root_idx])\n",
    "        # fidelity_minus[sparsity_percent] = fidelity(pred_orig, , y[root_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b659d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f57aa1ffb10>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(*zip(*fidelity_minus.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a84f2dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1428571492433548]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286da346",
   "metadata": {},
   "source": [
    "get a thorough evluation setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142110ca",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
