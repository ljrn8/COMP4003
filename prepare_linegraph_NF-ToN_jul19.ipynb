{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6267a742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dgl\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf4f47c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import networkx as nx \n",
    "from torch_geometric.utils.convert import from_dgl\n",
    "\n",
    "# run this function per-epoch, per-chunk\n",
    "def to_graph(data):\n",
    "    # assumes 'h' is already processed\n",
    "    # attrs = [c for c in data.columns if c not in (\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\")]\n",
    "    # data['h'] = data[attrs].values.tolist()\n",
    "    \n",
    "    data['h'] = data['h'].apply(lambda x: np.array(x, dtype=np.float32))\n",
    "    data['Attack'] = data['Attack'].astype(np.int64)\n",
    "    \n",
    "    data = data.rename(columns={'h': 'x'})\n",
    "    \n",
    "    G = nx.from_pandas_edgelist(data, source='IPV4_SRC_ADDR', \n",
    "                                target='IPV4_DST_ADDR', \n",
    "                                edge_attr=['x', 'Attack'], \n",
    "                                create_using=nx.MultiGraph())\n",
    "    G = G.to_directed()\n",
    "\n",
    "    g = dgl.from_networkx(G, edge_attrs=['x', 'Attack'])\n",
    "    g = g.line_graph(shared=True)\n",
    "\n",
    "    # run this during training\n",
    "    # return from_dgl(g)\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b86335ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight \n",
    "from torch import nn\n",
    "import torch as th\n",
    "\n",
    "classes_df = pd.read_csv('raw/NF-ToN-IoT-v3.csv', dtype='category', usecols=['Attack'])\n",
    "unique_classes = np.array(classes_df['Attack'].unique())\n",
    "\n",
    "# weighted cross entropy loss\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "           class_weight= 'balanced',\n",
    "            classes=unique_classes,\n",
    "            y=classes_df['Attack'])\n",
    "\n",
    "class_weights = th.FloatTensor(class_weights)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae61fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "del classes_df # memory risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fb24693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Benign' 'scanning' 'dos' 'injection' 'ddos' 'password' 'xss'\n",
      " 'ransomware' 'Backdoor' 'mitm']\n"
     ]
    }
   ],
   "source": [
    "print(unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "69b167d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "from EGraphSAGE import Preprocessing\n",
    "\n",
    "f = 'raw/NF-ToN-IoT-v3.csv'\n",
    "for chunk0 in pd.read_csv(f, chunksize=10_000):\n",
    "    break\n",
    "\n",
    "print('loaded')\n",
    "chunk0 = Preprocessing._prepare_flows(chunk0)\n",
    "G0 = to_graph(chunk0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "287cdb6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphSAGE(50, 10, num_layers=2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import GraphSAGE\n",
    "\n",
    "model = GraphSAGE(\n",
    "    in_channels=G0.ndata['x'].shape[1],\n",
    "    hidden_channels=64, # 128 in original EGraphSAGE paper\n",
    "    num_layers=2,\n",
    "    out_channels=len(unique_classes), # !! assumes ordered ?\n",
    "    dropout=0.2\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8db51df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [02:16,  1.73s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m2\u001b[39m):\n\u001b[32m     52\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/2\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     m = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\n\u001b[32m     57\u001b[39m \n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \n\u001b[32m     59\u001b[39m     \u001b[38;5;28mprint\u001b[39m(m)\n\u001b[32m     60\u001b[39m     metrics.append(m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, csv_file, criterion, chunksize, train)\u001b[39m\n\u001b[32m     10\u001b[39m losses, test_losses = [], []\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m tqdm(pd.read_csv(csv_file, chunksize=chunksize)):\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     chunk = \u001b[43mPreprocessing\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_prepare_flows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     G = to_graph(chunk)\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# all ones for edges\u001b[39;00m\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# G.edata['x'] = th.ones(G.num_edges(), G.ndata['x'].shape[1])\u001b[39;00m\n\u001b[32m     18\u001b[39m \n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m# reshape all data for batching\u001b[39;00m\n\u001b[32m     20\u001b[39m     \u001b[38;5;66;03m# G.ndata['h'] = th.reshape(G.ndata['h'], (G.ndata['h'].shape[0], 1 ,G.ndata['h'].shape[1]))\u001b[39;00m\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# G.edata['h'] = th.reshape(G.edata['h'], (G.edata['h'].shape[0], 1 ,G.edata['h'].shape[1]))\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/NIDS-HPO/EGraphSAGE.py:151\u001b[39m, in \u001b[36mPreprocessing._prepare_flows\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m pk_cols:\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m data.columns, \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in columns \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata.columns\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     data[k] = \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m data[\u001b[33m'\u001b[39m\u001b[33mIPV4_SRC_ADDR\u001b[39m\u001b[33m'\u001b[39m] = data[\u001b[33m'\u001b[39m\u001b[33mIPV4_SRC_ADDR\u001b[39m\u001b[33m'\u001b[39m] + \u001b[33m'\u001b[39m\u001b[33m:\u001b[39m\u001b[33m'\u001b[39m + data[\u001b[33m'\u001b[39m\u001b[33mL4_SRC_PORT\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    154\u001b[39m data[\u001b[33m'\u001b[39m\u001b[33mIPV4_DST_ADDR\u001b[39m\u001b[33m'\u001b[39m] = data[\u001b[33m'\u001b[39m\u001b[33mIPV4_DST_ADDR\u001b[39m\u001b[33m'\u001b[39m] + \u001b[33m'\u001b[39m\u001b[33m:\u001b[39m\u001b[33m'\u001b[39m + data[\u001b[33m'\u001b[39m\u001b[33mL4_DST_PORT\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/NIDS-HPO/venv/lib/python3.11/site-packages/pandas/core/series.py:4935\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4800\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4801\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4802\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4807\u001b[39m     **kwargs,\n\u001b[32m   4808\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4809\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4810\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4811\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4926\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4927\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4928\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4929\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4930\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4931\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4932\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4933\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4934\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4935\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/NIDS-HPO/venv/lib/python3.11/site-packages/pandas/core/apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/NIDS-HPO/venv/lib/python3.11/site-packages/pandas/core/apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/NIDS-HPO/venv/lib/python3.11/site-packages/pandas/core/base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/NIDS-HPO/venv/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "from tqdm import tqdm\n",
    "from EGraphSAGE import Model\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_one_epoch(model, csv_file, criterion, chunksize=10_000, train=0.8):\n",
    "    optimizer = th.optim.Adam(model.parameters())\n",
    "    model.train()\n",
    "    \n",
    "    losses, test_losses = [], []\n",
    "    \n",
    "    for chunk in tqdm(pd.read_csv(csv_file, chunksize=chunksize)):\n",
    "        chunk = Preprocessing._prepare_flows(chunk)\n",
    "        G = to_graph(chunk)\n",
    "        \n",
    "        # all ones for edges\n",
    "        # G.edata['x'] = th.ones(G.num_edges(), G.ndata['x'].shape[1])\n",
    "        \n",
    "        # reshape all data for batching\n",
    "        # G.ndata['h'] = th.reshape(G.ndata['h'], (G.ndata['h'].shape[0], 1 ,G.ndata['h'].shape[1]))\n",
    "        # G.edata['h'] = th.reshape(G.edata['h'], (G.edata['h'].shape[0], 1 ,G.edata['h'].shape[1]))\n",
    "        \n",
    "        size = G.number_of_nodes()\n",
    "        train_mask = np.zeros(size)\n",
    "        train_mask[:int(size*train)] = 1\n",
    "        test_mask = ~np.array(train_mask, dtype=bool)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        labels =  G.ndata['Attack']\n",
    "\n",
    "        G = from_dgl(G)\n",
    "        pred = model(G.x, G.edge_index)\n",
    "        \n",
    "        loss = criterion(pred[train_mask, :], labels[train_mask])\n",
    "        test_loss = criterion(pred[test_mask, :], labels[test_mask])\n",
    "        \n",
    "\n",
    "        losses.append(loss)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        del chunk\n",
    "        del G\n",
    "\n",
    "    return losses, test_losses\n",
    "\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for epoch in range(2):\n",
    "    print(f'epoch {epoch+1}/2')\n",
    "    m = train_one_epoch(\n",
    "        model=model,\n",
    "        csv_file=f,\n",
    "        criterion=criterion\n",
    "        \n",
    "    )  \n",
    "    print(m)\n",
    "    metrics.append(m)\n",
    "    \n",
    "    \n",
    "# !! most of the time is in preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "306fe3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1190494"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G0.number_of_edges()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
