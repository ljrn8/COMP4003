{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c304f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "import torch as th\n",
    "from torch_geometric.explain import Explainer, CaptumExplainer\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa87dc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taznk/COMP4003/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/taznk/COMP4003/venv/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    }
   ],
   "source": [
    "with open('interm/BoT-IoT_reduced_graph.pkl', 'rb') as f:\n",
    "    G = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "315749be",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_line = G.line_graph(shared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cb64495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148792, 134710628)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_line.number_of_nodes(), G_line.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ce81d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_152691/1449081621.py:11: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  pyG_line.test_mask = ~np.array(pyG_line.train_mask, dtype=bool)\n",
      "/home/taznk/COMP4003/venv/lib/python3.11/site-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
      "  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 37514], x=[21821, 49], Attack=[21821], train_mask=[21821], test_mask=[21821], n_id=[21821], e_id=[37514], input_id=[128], batch_size=128)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.utils import from_dgl\n",
    "import numpy as np \n",
    "\n",
    "# train mask\n",
    "pyG_line = from_dgl(G_line)\n",
    "nodes = G_line.number_of_nodes()\n",
    "train_amount = int(0.8*G_line.number_of_nodes())\n",
    "pyG_line.train_mask = torch.BoolTensor([False] * nodes)\n",
    "pyG_line.train_mask[:train_amount] = True\n",
    "pyG_line.test_mask = ~np.array(pyG_line.train_mask, dtype=bool)\n",
    "\n",
    "loader = NeighborLoader(\n",
    "    pyG_line,\n",
    "    num_neighbors=[10] * 3,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=6,\n",
    "    input_nodes=pyG_line.train_mask\n",
    ")\n",
    "\n",
    "# !!! more samples ??\n",
    "test_loader = NeighborLoader(\n",
    "    pyG_line,\n",
    "    num_neighbors=[10] * 3,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=6,\n",
    "    input_nodes=pyG_line.test_mask\n",
    ")\n",
    "\n",
    "batch = next(iter(loader))\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "485a6f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 930/930 [00:31<00:00, 29.11it/s]\n",
      "100%|██████████| 1163/1163 [00:18<00:00, 61.40it/s]\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.nn.models.basic_gnn import GraphSAGE\n",
    "\n",
    "g = pyG_line\n",
    "\n",
    "model = GraphSAGE(\n",
    "    49,\n",
    "    hidden_channels=64,\n",
    "    out_channels=5,\n",
    "    num_layers=3,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "def train_epoch(model, train_loader, test_loader):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch = batch.to(device)   \n",
    "        out= model( batch.x.to(device), batch.edge_index.to(device))\n",
    "        out = out[:batch.batch_size]\n",
    "        y = batch.Attack[:batch.batch_size]\n",
    "\n",
    "        loss = F.cross_entropy(out, y)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        del batch\n",
    "        \n",
    "    total_test_loss = 0\n",
    "    for batch in tqdm(test_loader):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(batch.x.to(device), batch.edge_index.to(device))\n",
    "            out = out[:batch.batch_size]\n",
    "            y = batch.Attack[:batch.batch_size]\n",
    "            total_test_loss += F.cross_entropy(out, y)\n",
    "        \n",
    "        del batch\n",
    "        \n",
    "    return total_loss / 128, total_test_loss / 128\n",
    "\n",
    "loss, test_loss = train_epoch(model, loader, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878334d4",
   "metadata": {},
   "source": [
    "### when using the explainer, will it load in all edges into memory ?? how does the overflow even happen ?? !! what are the  preprocessing steps from the given paper EXACTLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71500708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8096078093803953, tensor(0.))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37d15d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 930/930 [00:32<00:00, 28.62it/s]\n",
      "100%|██████████| 1163/1163 [00:16<00:00, 69.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2J"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAH6FJREFUeJzt3X90U/Xh//FXWmgKQlNYJYUS7BQV8UfrWhrrjh/mMVp32IQdd+w4almPwykMPYvzQKdrp54tKMzVI51Mjhw3PY5Oj9OdyerZgpyjEq2UoSA/HE6hiEmpSoJVW5a8v3/4JSzSYoMt76Y8H+fc47h9v5P3vaeHPne5uXUYY4wAAAAsybK9AAAAcHIjRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGDVCNsL6I9EIqF9+/Zp7NixcjgctpcDAAD6wRijgwcPatKkScrK6vv6R0bEyL59++TxeGwvAwAAHIf29nZNnjy5z69nRIyMHTtW0ucHk5eXZ3k1AACgP2KxmDweT/LneF8yIkYO/9NMXl4eMQIAQIb5slssuIEVAABYRYwAAACrjitGmpqaVFxcrNzcXHm9XrW2th5z/IEDB7Rw4UJNnDhRTqdTZ511ltauXXtcCwYAAMNL2veMNDc3y+/3a+XKlfJ6vWpsbFRVVZV27typCRMmHDW+p6dHl19+uSZMmKCnnnpKRUVF2r17t/Lz8wdi/QAAIMM5jDEmnQler1czZszQihUrJH3+DBCPx6NFixZpyZIlR41fuXKlli1bph07dmjkyJHHtchYLCaXy6VoNMoNrAAAZIj+/vxO659penp61NbWJp/Pd+QFsrLk8/kUCoV6nfPXv/5VlZWVWrhwodxut8477zz9+te/VjweT+etAQDAMJXWP9N0dnYqHo/L7Xan7He73dqxY0evc/7zn/9o3bp1uvbaa7V27Vrt2rVLCxYs0KFDh9TQ0NDrnO7ubnV3dyf/HIvF0lkmAADIIIP+aZpEIqEJEybo4YcfVllZmaqrq3XHHXdo5cqVfc4JBAJyuVzJjaevAgAwfKUVIwUFBcrOzlYkEknZH4lEVFhY2OuciRMn6qyzzlJ2dnZy3znnnKNwOKyenp5e59TV1SkajSa39vb2dJYJAAAySFoxkpOTo7KyMgWDweS+RCKhYDCoysrKXud885vf1K5du5RIJJL73nrrLU2cOFE5OTm9znE6ncmnrfLUVQAAhre0/5nG7/dr1apV+sMf/qDt27fr5ptvVldXl2prayVJNTU1qqurS46/+eab9eGHH+rWW2/VW2+9peeee06//vWvtXDhwoE7CgAAkLHSfs5IdXW19u/fr/r6eoXDYZWWlqqlpSV5U+uePXtSfk2wx+PR888/r5/+9Ke64IILVFRUpFtvvVWLFy8euKMAAAAZK+3njNjAc0YAAMg8g/KcEQAAgIFGjAAAAKuIEQAAYBUxAgAArCJGAACAVcQIAACwihgBAABWESMAAMAqYgQAAFhFjAAAAKuIEQAAYBUxAgAArCJGAACAVcQIAACwihgBAABWESMAAMAqYgQAAFhFjAAAAKuIEQAAYBUxAgAArCJGAACAVcQIAACwihgBAABWESMAAMAqYgQAAFhFjAAAAKuIEQAAYBUxAgAArCJGAACAVcQIAACwihgBAABWESMAAMAqYgQAAFhFjAAAAKuIEQAAYBUxAgAArCJGAACAVcQIAACwihgBAABWESMAAMAqYgQAAFhFjAAAAKuIEQAAYBUxAgAArCJGAACAVcQIAACwihgBAABWHVeMNDU1qbi4WLm5ufJ6vWptbe1z7KOPPiqHw5Gy5ebmHveCAQDA8JJ2jDQ3N8vv96uhoUGbNm1SSUmJqqqq1NHR0eecvLw8vf/++8lt9+7dX2nRAABg+Eg7Ru6//37Nnz9ftbW1mj59ulauXKnRo0dr9erVfc5xOBwqLCxMbm63+ystGgAADB9pxUhPT4/a2trk8/mOvEBWlnw+n0KhUJ/zPv74Y5122mnyeDyaPXu23nzzzWO+T3d3t2KxWMoGAACGp7RipLOzU/F4/KgrG263W+FwuNc5Z599tlavXq1nn31Wjz/+uBKJhC6++GLt3bu3z/cJBAJyuVzJzePxpLNMAACQQQb90zSVlZWqqalRaWmpZs6cqaefflqnnnqqfv/73/c5p66uTtFoNLm1t7cP9jIBAIAlI9IZXFBQoOzsbEUikZT9kUhEhYWF/XqNkSNH6sILL9SuXbv6HON0OuV0OtNZGgAAyFBpXRnJyclRWVmZgsFgcl8ikVAwGFRlZWW/XiMej2vLli2aOHFieisFAADDUlpXRiTJ7/dr3rx5Ki8vV0VFhRobG9XV1aXa2lpJUk1NjYqKihQIBCRJd999ty666CJNnTpVBw4c0LJly7R792796Ec/GtgjAQAAGSntGKmurtb+/ftVX1+vcDis0tJStbS0JG9q3bNnj7Kyjlxw+eijjzR//nyFw2GNGzdOZWVl2rBhg6ZPnz5wRwEAADKWwxhjbC/iy8RiMblcLkWjUeXl5dleDgAA6If+/vzmd9MAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVh1XjDQ1Nam4uFi5ubnyer1qbW3t17w1a9bI4XBozpw5x/O2AABgGEo7Rpqbm+X3+9XQ0KBNmzappKREVVVV6ujoOOa8d999Vz/72c90ySWXHPdiAQDA8JN2jNx///2aP3++amtrNX36dK1cuVKjR4/W6tWr+5wTj8d17bXX6q677tLpp5/+lRYMAACGl7RipKenR21tbfL5fEdeICtLPp9PoVCoz3l33323JkyYoBtuuKFf79Pd3a1YLJayAQCA4SmtGOns7FQ8Hpfb7U7Z73a7FQ6He53z0ksv6ZFHHtGqVav6/T6BQEAulyu5eTyedJYJAAAyyKB+mubgwYO6/vrrtWrVKhUUFPR7Xl1dnaLRaHJrb28fxFUCAACbRqQzuKCgQNnZ2YpEIin7I5GICgsLjxr/9ttv691339V3v/vd5L5EIvH5G48YoZ07d+qMM844ap7T6ZTT6UxnaQAAIEOldWUkJydHZWVlCgaDyX2JRELBYFCVlZVHjZ82bZq2bNmizZs3J7errrpKl156qTZv3sw/vwAAgPSujEiS3+/XvHnzVF5eroqKCjU2Nqqrq0u1tbWSpJqaGhUVFSkQCCg3N1fnnXdeyvz8/HxJOmo/AAA4OaUdI9XV1dq/f7/q6+sVDodVWlqqlpaW5E2te/bsUVYWD3YFAAD94zDGGNuL+DKxWEwul0vRaFR5eXm2lwMAAPqhvz+/uYQBAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWHVcMdLU1KTi4mLl5ubK6/WqtbW1z7FPP/20ysvLlZ+fr1NOOUWlpaV67LHHjnvBAABgeEk7Rpqbm+X3+9XQ0KBNmzappKREVVVV6ujo6HX8+PHjdccddygUCumNN95QbW2tamtr9fzzz3/lxQMAgMznMMaYdCZ4vV7NmDFDK1askCQlEgl5PB4tWrRIS5Ys6ddrfOMb39CsWbN0zz339Gt8LBaTy+VSNBpVXl5eOssFAACW9Pfnd1pXRnp6etTW1iafz3fkBbKy5PP5FAqFvnS+MUbBYFA7d+7U//3f//U5rru7W7FYLGUDAADDU1ox0tnZqXg8LrfbnbLf7XYrHA73OS8ajWrMmDHKycnRrFmz9OCDD+ryyy/vc3wgEJDL5UpuHo8nnWUCAIAMckI+TTN27Fht3rxZr732mn71q1/J7/dr/fr1fY6vq6tTNBpNbu3t7SdimQAAwIIR6QwuKChQdna2IpFIyv5IJKLCwsI+52VlZWnq1KmSpNLSUm3fvl2BQEDf+ta3eh3vdDrldDrTWRoAAMhQaV0ZycnJUVlZmYLBYHJfIpFQMBhUZWVlv18nkUiou7s7nbcGAADDVFpXRiTJ7/dr3rx5Ki8vV0VFhRobG9XV1aXa2lpJUk1NjYqKihQIBCR9fv9HeXm5zjjjDHV3d2vt2rV67LHH9NBDDw3skQAAgIyUdoxUV1dr//79qq+vVzgcVmlpqVpaWpI3te7Zs0dZWUcuuHR1dWnBggXau3evRo0apWnTpunxxx9XdXX1wB0FAADIWGk/Z8QGnjMCAEDmGZTnjAAAAAw0YgQAAFhFjAAAAKuIEQAAYBUxAgAArCJGAACAVcQIAACwihgBAABWESMAAMAqYgQAAFhFjAAAAKuIEQAAYBUxAgAArCJGAACAVcQIAACwihgBAABWESMAAMAqYgQAAFhFjAAAAKuIEQAAYBUxAgAArCJGAACAVcQIAACwihgBAABWESMAAMAqYgQAAFhFjAAAAKuIEQAAYBUxAgAArCJGAACAVcQIAACwihgBAABWESMAAMAqYgQAAFhFjAAAAKuIEQAAYBUxAgAArCJGAACAVcQIAACwihgBAABWESMAAMAqYgQAAFhFjAAAAKuIEQAAYBUxAgAArCJGAACAVccVI01NTSouLlZubq68Xq9aW1v7HLtq1SpdcsklGjdunMaNGyefz3fM8QAA4OSSdow0NzfL7/eroaFBmzZtUklJiaqqqtTR0dHr+PXr12vu3Ll64YUXFAqF5PF4dMUVV+i99977yosHAACZz2GMMelM8Hq9mjFjhlasWCFJSiQS8ng8WrRokZYsWfKl8+PxuMaNG6cVK1aopqamX+8Zi8XkcrkUjUaVl5eXznIBAIAl/f35ndaVkZ6eHrW1tcnn8x15gaws+Xw+hUKhfr3GJ598okOHDmn8+PF9junu7lYsFkvZAADA8JRWjHR2dioej8vtdqfsd7vdCofD/XqNxYsXa9KkSSlB80WBQEAulyu5eTyedJYJAAAyyAn9NM3SpUu1Zs0a/eUvf1Fubm6f4+rq6hSNRpNbe3v7CVwlAAA4kUakM7igoEDZ2dmKRCIp+yORiAoLC485d/ny5Vq6dKn++c9/6oILLjjmWKfTKafTmc7SAABAhkrrykhOTo7KysoUDAaT+xKJhILBoCorK/ucd9999+mee+5RS0uLysvLj3+1AABg2Enryogk+f1+zZs3T+Xl5aqoqFBjY6O6urpUW1srSaqpqVFRUZECgYAk6d5771V9fb2eeOIJFRcXJ+8tGTNmjMaMGTOAhwIAADJR2jFSXV2t/fv3q76+XuFwWKWlpWppaUne1Lpnzx5lZR254PLQQw+pp6dH3//+91Nep6GhQb/85S+/2uoBAEDGS/s5IzbwnBEAADLPoDxnBAAAYKARIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsOq4YaWpqUnFxsXJzc+X1etXa2trn2DfffFNXX321iouL5XA41NjYeLxrBQAAw1DaMdLc3Cy/36+GhgZt2rRJJSUlqqqqUkdHR6/jP/nkE51++ulaunSpCgsLv/KCAQDA8JJ2jNx///2aP3++amtrNX36dK1cuVKjR4/W6tWrex0/Y8YMLVu2TD/4wQ/kdDq/8oIBAMDwklaM9PT0qK2tTT6f78gLZGXJ5/MpFAoN2KK6u7sVi8VSNgAAMDylFSOdnZ2Kx+Nyu90p+91ut8Lh8IAtKhAIyOVyJTePxzNgrw0AAIaWIflpmrq6OkWj0eTW3t5ue0kAAGCQjEhncEFBgbKzsxWJRFL2RyKRAb051el0cn8JAAAnibSujOTk5KisrEzBYDC5L5FIKBgMqrKycsAXBwAAhr+0roxIkt/v17x581ReXq6Kigo1Njaqq6tLtbW1kqSamhoVFRUpEAhI+vym123btiX/93vvvafNmzdrzJgxmjp16gAeCgAAyERpx0h1dbX279+v+vp6hcNhlZaWqqWlJXlT6549e5SVdeSCy759+3ThhRcm/7x8+XItX75cM2fO1Pr167/6EQAAgIzmMMYY24v4MrFYTC6XS9FoVHl5ebaXAwAA+qG/P7+H5KdpAADAyYMYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGDVccVIU1OTiouLlZubK6/Xq9bW1mOOf/LJJzVt2jTl5ubq/PPP19q1a49rsQAAYPhJO0aam5vl9/vV0NCgTZs2qaSkRFVVVero6Oh1/IYNGzR37lzdcMMN+te//qU5c+Zozpw52rp161dePAAAyHwOY4xJZ4LX69WMGTO0YsUKSVIikZDH49GiRYu0ZMmSo8ZXV1erq6tLf/vb35L7LrroIpWWlmrlypX9es9YLCaXy6VoNKq8vLx0lgsAACzp78/vtK6M9PT0qK2tTT6f78gLZGXJ5/MpFAr1OicUCqWMl6Sqqqo+x0tSd3e3YrFYygYAAIantGKks7NT8Xhcbrc7Zb/b7VY4HO51TjgcTmu8JAUCAblcruTm8XjSWSYAAMggQ/LTNHV1dYpGo8mtvb3d9pIAAMAgGZHO4IKCAmVnZysSiaTsj0QiKiws7HVOYWFhWuMlyel0yul0prM0AACQodK6MpKTk6OysjIFg8HkvkQioWAwqMrKyl7nVFZWpoyXpH/84x99jgcAACeXtK6MSJLf79e8efNUXl6uiooKNTY2qqurS7W1tZKkmpoaFRUVKRAISJJuvfVWzZw5U7/5zW80a9YsrVmzRhs3btTDDz88sEcCAAAyUtoxUl1drf3796u+vl7hcFilpaVqaWlJ3qS6Z88eZWUdueBy8cUX64knntCdd96pn//85zrzzDP1zDPP6Lzzzhu4owAAABkr7eeM2MBzRgAAyDyD8pwRAACAgUaMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWJX24+BtOPyQ2FgsZnklAACgvw7/3P6yh71nRIwcPHhQkuTxeCyvBAAApOvgwYNyuVx9fj0jfjdNIpHQvn37NHbsWDkcDtvLsSoWi8nj8ai9vZ3f0zPIONcnBuf5xOA8nxic51TGGB08eFCTJk1K+SW6X5QRV0aysrI0efJk28sYUvLy8vhGP0E41ycG5/nE4DyfGJznI451ReQwbmAFAABWESMAAMAqYiTDOJ1ONTQ0yOl02l7KsMe5PjE4zycG5/nE4Dwfn4y4gRUAAAxfXBkBAABWESMAAMAqYgQAAFhFjAAAAKuIkSHoww8/1LXXXqu8vDzl5+frhhtu0Mcff3zMOZ999pkWLlyor33taxozZoyuvvpqRSKRXsd+8MEHmjx5shwOhw4cODAIR5AZBuM8v/7665o7d648Ho9GjRqlc845Rw888MBgH8qQ0tTUpOLiYuXm5srr9aq1tfWY45988klNmzZNubm5Ov/887V27dqUrxtjVF9fr4kTJ2rUqFHy+Xz697//PZiHkBEG8jwfOnRIixcv1vnnn69TTjlFkyZNUk1Njfbt2zfYh5ERBvp7+n/ddNNNcjgcamxsHOBVZxiDIefKK680JSUl5pVXXjEvvviimTp1qpk7d+4x59x0003G4/GYYDBoNm7caC666CJz8cUX9zp29uzZ5tvf/raRZD766KNBOILMMBjn+ZFHHjG33HKLWb9+vXn77bfNY489ZkaNGmUefPDBwT6cIWHNmjUmJyfHrF692rz55ptm/vz5Jj8/30QikV7Hv/zyyyY7O9vcd999Ztu2bebOO+80I0eONFu2bEmOWbp0qXG5XOaZZ54xr7/+urnqqqvM17/+dfPpp5+eqMMacgb6PB84cMD4fD7T3NxsduzYYUKhkKmoqDBlZWUn8rCGpMH4nj7s6aefNiUlJWbSpEnmt7/97SAfydBGjAwx27ZtM5LMa6+9ltz397//3TgcDvPee+/1OufAgQNm5MiR5sknn0zu2759u5FkQqFQytjf/e53ZubMmSYYDJ7UMTLY5/l/LViwwFx66aUDt/ghrKKiwixcuDD553g8biZNmmQCgUCv46+55hoza9aslH1er9f8+Mc/NsYYk0gkTGFhoVm2bFny6wcOHDBOp9P86U9/GoQjyAwDfZ5709raaiSZ3bt3D8yiM9Rgneu9e/eaoqIis3XrVnPaaaed9DHCP9MMMaFQSPn5+SovL0/u8/l8ysrK0quvvtrrnLa2Nh06dEg+ny+5b9q0aZoyZYpCoVBy37Zt23T33Xfrj3/84zF/YdHJYDDP8xdFo1GNHz9+4BY/RPX09KitrS3l/GRlZcnn8/V5fkKhUMp4SaqqqkqOf+eddxQOh1PGuFwueb3eY57z4WwwznNvotGoHA6H8vPzB2TdmWiwznUikdD111+v22+/Xeeee+7gLD7DnNw/kYagcDisCRMmpOwbMWKExo8fr3A43OecnJyco/7ScLvdyTnd3d2aO3euli1bpilTpgzK2jPJYJ3nL9qwYYOam5t14403Dsi6h7LOzk7F43G53e6U/cc6P+Fw+JjjD/83ndcc7gbjPH/RZ599psWLF2vu3Lkn9S97G6xzfe+992rEiBG65ZZbBn7RGYoYOUGWLFkih8NxzG3Hjh2D9v51dXU655xzdN111w3aewwFts/z/9q6datmz56thoYGXXHFFSfkPYGv6tChQ7rmmmtkjNFDDz1keznDTltbmx544AE9+uijcjgctpczZIywvYCTxW233aYf/vCHxxxz+umnq7CwUB0dHSn7//vf/+rDDz9UYWFhr/MKCwvV09OjAwcOpPy/9kgkkpyzbt06bdmyRU899ZSkzz+hIEkFBQW64447dNdddx3nkQ0tts/zYdu2bdNll12mG2+8UXfeeedxHUumKSgoUHZ29lGf4urt/BxWWFh4zPGH/xuJRDRx4sSUMaWlpQO4+swxGOf5sMMhsnv3bq1bt+6kvioiDc65fvHFF9XR0ZFyhToej+u2225TY2Oj3n333YE9iExh+6YVpDp8Y+XGjRuT+55//vl+3Vj51FNPJfft2LEj5cbKXbt2mS1btiS31atXG0lmw4YNfd4VPpwN1nk2xpitW7eaCRMmmNtvv33wDmCIqqioMD/5yU+Sf47H46aoqOiYN/t95zvfSdlXWVl51A2sy5cvT349Go1yA+sAn2djjOnp6TFz5swx5557runo6BichWeggT7XnZ2dKX8Xb9myxUyaNMksXrzY7NixY/AOZIgjRoagK6+80lx44YXm1VdfNS+99JI588wzUz5yunfvXnP22WebV199NbnvpptuMlOmTDHr1q0zGzduNJWVlaaysrLP93jhhRdO6k/TGDM453nLli3m1FNPNdddd515//33k9vJ8pf7mjVrjNPpNI8++qjZtm2bufHGG01+fr4Jh8PGGGOuv/56s2TJkuT4l19+2YwYMcIsX77cbN++3TQ0NPT60d78/Hzz7LPPmjfeeMPMnj2bj/YO8Hnu6ekxV111lZk8ebLZvHlzyvdud3e3lWMcKgbje/qL+DQNMTIkffDBB2bu3LlmzJgxJi8vz9TW1pqDBw8mv/7OO+8YSeaFF15I7vv000/NggULzLhx48zo0aPN9773PfP+++/3+R7EyOCc54aGBiPpqO200047gUdm14MPPmimTJlicnJyTEVFhXnllVeSX5s5c6aZN29eyvg///nP5qyzzjI5OTnm3HPPNc8991zK1xOJhPnFL35h3G63cTqd5rLLLjM7d+48EYcypA3keT78vd7b9r/f/yergf6e/iJixBiHMf//5gEAAAAL+DQNAACwihgBAABWESMAAMAqYgQAAFhFjAAAAKuIEQAAYBUxAgAArCJGAACAVcQIAACwihgBAABWESMAAMAqYgQAAFj1/wByybFICW4Q/AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 930/930 [00:34<00:00, 27.14it/s]\n",
      " 98%|█████████▊| 1144/1163 [00:18<00:00, 62.06it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m l, tl = [], []\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     loss, test_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     l.append(loss)\n\u001b[32m      8\u001b[39m     tl.append(test_loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, train_loader, test_loader)\u001b[39m\n\u001b[32m     40\u001b[39m model.eval()\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m     out = out[:batch.batch_size]\n\u001b[32m     44\u001b[39m     y = batch.Attack[:batch.batch_size]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch_geometric/nn/models/basic_gnn.py:256\u001b[39m, in \u001b[36mBasicGNN.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_weight, edge_attr, batch, batch_size, num_sampled_nodes_per_hop, num_sampled_edges_per_hop)\u001b[39m\n\u001b[32m    254\u001b[39m     x = conv(x, edge_index, edge_attr=edge_attr)\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     x = \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i < \u001b[38;5;28mself\u001b[39m.num_layers - \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.jk_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    259\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.act \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.act_first:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch_geometric/nn/conv/sage_conv.py:134\u001b[39m, in \u001b[36mSAGEConv.forward\u001b[39m\u001b[34m(self, x, edge_index, size)\u001b[39m\n\u001b[32m    131\u001b[39m     x = (\u001b[38;5;28mself\u001b[39m.lin(x[\u001b[32m0\u001b[39m]).relu(), x[\u001b[32m1\u001b[39m])\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m out = \u001b[38;5;28mself\u001b[39m.lin_l(out)\n\u001b[32m    137\u001b[39m x_r = x[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/tmp/torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_cyif1jog.py:229\u001b[39m, in \u001b[36mpropagate\u001b[39m\u001b[34m(self, edge_index, x, size)\u001b[39m\n\u001b[32m    221\u001b[39m             kwargs = CollectArgs(\n\u001b[32m    222\u001b[39m                 x_j=kwargs.x_j,\n\u001b[32m    223\u001b[39m                 index=hook_kwargs[\u001b[33m'\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    224\u001b[39m                 ptr=hook_kwargs[\u001b[33m'\u001b[39m\u001b[33mptr\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    225\u001b[39m                 dim_size=hook_kwargs[\u001b[33m'\u001b[39m\u001b[33mdim_size\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    226\u001b[39m             )\n\u001b[32m    227\u001b[39m \u001b[38;5;66;03m# End Aggregate Forward Pre Hook #######################################\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;66;03m# Begin Aggregate Forward Hook #########################################\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:594\u001b[39m, in \u001b[36mMessagePassing.aggregate\u001b[39m\u001b[34m(self, inputs, index, ptr, dim_size)\u001b[39m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maggregate\u001b[39m(\n\u001b[32m    578\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    579\u001b[39m     inputs: Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    582\u001b[39m     dim_size: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    583\u001b[39m ) -> Tensor:\n\u001b[32m    584\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[32m    585\u001b[39m \u001b[33;03m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[32m    586\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    592\u001b[39m \u001b[33;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[32m    593\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m594\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maggr_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch_geometric/experimental.py:117\u001b[39m, in \u001b[36mdisable_dynamic_shapes.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: Any, **kwargs: Any) -> Any:\n\u001b[32m    116\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_experimental_mode_enabled(\u001b[33m'\u001b[39m\u001b[33mdisable_dynamic_shapes\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m required_arg \u001b[38;5;129;01min\u001b[39;00m required_args:\n\u001b[32m    120\u001b[39m         index = required_args_pos[required_arg]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch_geometric/nn/aggr/base.py:131\u001b[39m, in \u001b[36mAggregation.__call__\u001b[39m\u001b[34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m     dim_size = \u001b[38;5;28mint\u001b[39m(index.max()) + \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index.numel() > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch_geometric/nn/aggr/basic.py:36\u001b[39m, in \u001b[36mMeanAggregation.forward\u001b[39m\u001b[34m(self, x, index, ptr, dim_size, dim)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, index: Optional[Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     34\u001b[39m             ptr: Optional[Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m, dim_size: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     35\u001b[39m             dim: \u001b[38;5;28mint\u001b[39m = -\u001b[32m2\u001b[39m) -> Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch_geometric/nn/aggr/base.py:185\u001b[39m, in \u001b[36mAggregation.reduce\u001b[39m\u001b[34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAggregation requires \u001b[39m\u001b[33m'\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to be specified\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP4003/venv/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:83\u001b[39m, in \u001b[36mscatter\u001b[39m\u001b[34m(src, index, dim, dim_size, reduce)\u001b[39m\n\u001b[32m     80\u001b[39m     count = count.clamp(\u001b[38;5;28mmin\u001b[39m=\u001b[32m1\u001b[39m)\n\u001b[32m     82\u001b[39m     index = broadcast(index, src, dim)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     out = \u001b[43msrc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnew_zeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscatter_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out / broadcast(count, out, dim)\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# For \"min\" and \"max\" reduction, we prefer `scatter_reduce_` on CPU or\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# in case the input does not require gradients:\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "l, tl = [], []\n",
    "for epoch in range(10):\n",
    "    loss, test_loss = train_epoch(model, loader, test_loader)\n",
    "    l.append(loss)\n",
    "    tl.append(test_loss)\n",
    "    print(np.array(l).mean(), np.array(tl).mean())\n",
    "    \n",
    "plt.plot(l)\n",
    "plt.plot(tl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ed41d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
